{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fedb1815",
   "metadata": {},
   "source": [
    "This script trains model with positive and negative pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b829219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['FOR_DISABLE_CONSOLE_CTRL_HANDLER'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import torch\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from datetime import datetime\n",
    "from sentence_transformers import losses, SentenceTransformer\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from modules.ModelFunctions import get_ST_model, auto_load_model\n",
    "from modules.timed_logger import logger\n",
    "from modules.metrics import evaluate_embedding_similarity_with_mrr\n",
    "from modules.STHardNegMiner import mine_negatives, _pairs_to_dataset\n",
    "from sentence_transformers.util import mine_hard_negatives\n",
    "from sentence_transformers import InputExample\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "def to_hf_dataset(dataset_iterable):\n",
    "    rows = []\n",
    "    for item in tqdm(dataset_iterable):\n",
    "        rows.append({\n",
    "            \"sentence1\": item[\"sentence1\"],\n",
    "            \"sentence2\": item[\"sentence2\"],\n",
    "            \"label\": int(item[\"label\"])   # ensure 0/1\n",
    "        })\n",
    "    ds = Dataset.from_list(rows)\n",
    "    # Ensure correct column order for the loss: [inputs..., label]\n",
    "    ds = ds.select_columns([\"sentence1\", \"sentence2\", \"label\"])\n",
    "    return ds\n",
    "\n",
    "\n",
    "\n",
    "logger.reset_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f482fcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = {\n",
    "    \"test_mode\": False,\n",
    "    \n",
    "    \"no_relation\": False,  # Disable relation data even if files exist or config says True\n",
    "    \"range_min\": 10,       # Minimum rank for candidate negatives\n",
    "    \"range_max\": 50,       # Maximum rank for candidate negatives\n",
    "    \"relative_margin\": 0.01,  # Relative margin for mining\n",
    "    \"num_neg_matching\": None,  # Negatives per anchor for matching mining (override)\n",
    "    \"num_neg_relation\": None,  # Negatives per anchor for relation mining (override)\n",
    "    \"sampling_strategy\": \"top\",  # Negative sampling strategy from candidates\n",
    "    \"batch_size\": 256,      # Batch size for training\n",
    "    \"no_faiss\": False,           # Disable FAISS acceleration in miner\n",
    "    \"model_checkpoint\": \"none\",  # Path to model checkpoint to load (default: none - use HF base model)\n",
    "    \n",
    "    \n",
    "    \"use_relation\": True,\n",
    "    \"n_pos_matching\": 5,\n",
    "    \"n_neg_matching\": 5,\n",
    "    \"n_fp_matching\": 5,\n",
    "    \"n_pos_relation\": 5,\n",
    "    \"n_neg_relation\": 5,\n",
    "    \"n_fp_relation\": 5,\n",
    "    \n",
    "}\n",
    "\n",
    "args = SimpleNamespace(**args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d5430c",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3f379e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 15:10:28 - Loading Model (initial training) (Elapsed: 0.35s, Since last: 0.35s)\n",
      "2025-10-02 15:10:28 - Loading base model with special tokens: all-MiniLM-L6-v2 (Elapsed: 0.35s, Since last: 0.00s)\n",
      "2025-10-02 15:10:28 - Use pytorch device_name: cuda:0\n",
      "2025-10-02 15:10:28 - Load pretrained SentenceTransformer: models/all-MiniLM-L6-v2_ST_childof_parentof\\auto_save_1_20251001_164241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded latest auto-saved model from: models/all-MiniLM-L6-v2_ST_childof_parentof\\auto_save_1_20251001_164241\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logger.log(\"Loading Model (initial training)\")\n",
    "output_dir = f\"output/finetune_initial/{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "base_model = 'all-MiniLM-L6-v2'\n",
    "\n",
    "# Load model - use Hugging Face model directly or specified checkpoint\n",
    "if args.model_checkpoint and args.model_checkpoint != \"none\":\n",
    "    model, tokenizer = auto_load_model(args.model_checkpoint)\n",
    "else:\n",
    "    model, tokenizer = None, None\n",
    "\n",
    "if model is None:\n",
    "    # Load base ST model with special tokens for relation support\n",
    "    logger.log(f\"Loading base model with special tokens: {base_model}\")\n",
    "    model, tokenizer = get_ST_model(base_model)\n",
    "\n",
    "# start_epoch = args.epoch\n",
    "# start_batch_i = args.batch_i + 1\n",
    "# start_global_step = args.global_step + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b138204",
   "metadata": {},
   "source": [
    "# Load OMOP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d70badf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 15:10:29 - Loading training data (Elapsed: 0.84s, Since last: 0.49s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((160288, 2), (643319, 2), (566536, 5))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.log(\"Loading training data\")\n",
    "\n",
    "matching_base_path = \"data/matching\"\n",
    "relation_base_path = \"data/relation\"\n",
    "seed = 42\n",
    "\n",
    "\n",
    "target_concepts_path = os.path.join(matching_base_path, 'target_concepts.feather')\n",
    "target_concepts = pd.read_feather(target_concepts_path)\n",
    "matching_name_bridge = pd.read_feather(os.path.join(matching_base_path, 'condition_matching_name_bridge_train.feather'))\n",
    "matching_name_table = pd.read_feather(os.path.join(matching_base_path, 'condition_matching_name_table_train.feather'))\n",
    "\n",
    "target_concepts.shape, matching_name_bridge.shape, matching_name_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27353036",
   "metadata": {},
   "source": [
    "# Training dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24ceb096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PositiveDataset(length=276059, label=1, seed=42)\n",
      "{'sentence1': 'Epidermal burn of multiple sites of upper limb', 'sentence2': 'Corrosion of first degree of multiple sites of right shoulder and upper limb, except wrist and hand', 'label': 1}\n",
      "NegativeDataset(length=801440, seed=42)\n",
      "{'sentence1': 'Infection present (Deprecated)', 'sentence2': 'Familial Retinoblastomas', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "from modules.Dataset import PositiveDataset, NegativeDataset, CombinedDataset\n",
    "matching_pos = PositiveDataset(\n",
    "    target_concepts=target_concepts,\n",
    "    name_table=matching_name_table,\n",
    "    name_bridge=matching_name_bridge,\n",
    "    max_elements=args.n_pos_matching,\n",
    "    seed=seed\n",
    ")\n",
    "print(matching_pos)\n",
    "print(matching_pos[0])\n",
    "\n",
    "matching_neg = NegativeDataset(\n",
    "    target_concepts=target_concepts,\n",
    "    name_table=matching_name_table,\n",
    "    blacklist_bridge=matching_name_bridge,\n",
    "    max_elements=args.n_neg_matching,\n",
    "    seed=seed\n",
    ")\n",
    "print(matching_neg)\n",
    "print(matching_neg[0])\n",
    "\n",
    "\n",
    "# if args.test_mode:\n",
    "#     anchor_positive_match = anchor_positive_match.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97f353d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4056/276059 [00:00<00:06, 40451.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 276059/276059 [00:06<00:00, 41719.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence1', 'sentence2', 'label'],\n",
      "    num_rows: 276059\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801440/801440 [00:18<00:00, 43740.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence1', 'sentence2', 'label'],\n",
      "    num_rows: 801440\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "matching_pos_pairs = to_hf_dataset(matching_pos)\n",
    "print(matching_pos_pairs)\n",
    "matching_neg_pairs = to_hf_dataset(matching_neg)\n",
    "print(matching_neg_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e313ffd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PositiveDataset(length=135385, label=1, seed=42)\n",
      "{'sentence1': 'Meningococcal infectious disease', 'sentence2': '<|parent of|>Acute meningococcal pericarditis', 'label': 1}\n",
      "NegativeDataset(length=801440, seed=42)\n",
      "{'sentence1': 'Infection present (Deprecated)', 'sentence2': '<|parent of|>Papillary adenocarcinoma, NOS, of tonsillar fossa', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "name_table_relation = pd.read_feather(os.path.join(relation_base_path, 'name_table_relation.feather'))\n",
    "name_bridge_relation = pd.read_feather(os.path.join(relation_base_path, 'name_bridge_relation.feather'))\n",
    "if args.use_relation:\n",
    "    from modules.Dataset import PositiveDataset as RelPositiveDataset\n",
    "    from modules.Dataset import NegativeDataset as RelNegativeDataset\n",
    "    relation_pos = RelPositiveDataset(\n",
    "        target_concepts=target_concepts,\n",
    "        name_table=name_table_relation,\n",
    "        name_bridge=name_bridge_relation,\n",
    "        max_elements=args.n_pos_relation,\n",
    "        seed=seed\n",
    "    )\n",
    "    print(relation_pos)\n",
    "    print(relation_pos[0])\n",
    "\n",
    "    relation_neg = RelNegativeDataset(\n",
    "        target_concepts=target_concepts,\n",
    "        name_table=name_table_relation,\n",
    "        blacklist_bridge=name_bridge_relation,\n",
    "        max_elements=args.n_neg_relation,\n",
    "        seed=seed\n",
    "    )\n",
    "    print(relation_neg)\n",
    "    print(relation_neg[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4945dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/135385 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135385/135385 [00:03<00:00, 42606.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence1', 'sentence2', 'label'],\n",
      "    num_rows: 135385\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801440/801440 [00:18<00:00, 42676.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence1', 'sentence2', 'label'],\n",
      "    num_rows: 801440\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "if args.use_relation:\n",
    "    relation_pos_pairs = to_hf_dataset(relation_pos)\n",
    "    print(relation_pos_pairs)\n",
    "    relation_neg_pairs = to_hf_dataset(relation_neg)\n",
    "    print(relation_neg_pairs)\n",
    "else:\n",
    "    relation_pos_pairs = None\n",
    "    relation_neg_pairs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb697d41",
   "metadata": {},
   "source": [
    "## Combine and Create final training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4ed1508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label'],\n",
       "    num_rows: 2014324\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "if args.use_relation:\n",
    "    all_pairs = [matching_pos_pairs, matching_neg_pairs, relation_pos_pairs, relation_neg_pairs]\n",
    "else:\n",
    "    all_pairs = [matching_pos_pairs, matching_neg_pairs]\n",
    "    \n",
    "ds_all = concatenate_datasets(all_pairs)\n",
    "ds_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23314275",
   "metadata": {},
   "source": [
    "# Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f33cee4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 15:06:15 - Loading validation data (Elapsed: 27.39s, Since last: 27.39s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['corpus_name', 'query_name', 'corpus_id', 'query_id', 'label'], dtype='object')\n",
      "Index(['query_name', 'corpus_name', 'query_id', 'corpus_id', 'label'], dtype='object')\n",
      "Index(['query_name', 'corpus_name', 'query_id', 'corpus_id', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "logger.log(\"Loading validation data\")\n",
    "condition_matching_valid = pd.read_feather(os.path.join(matching_base_path, 'condition_matching_valid.feather'))\n",
    "print(condition_matching_valid.columns)\n",
    "\n",
    "condition_matching_train_subset = pd.read_feather(os.path.join(matching_base_path, 'condition_matching_train_subset.feather'))\n",
    "print(condition_matching_train_subset.columns)\n",
    "\n",
    "condition_relation_train_subset = pd.read_feather(os.path.join(relation_base_path, 'condition_relation_train_subset.feather'))\n",
    "print(condition_relation_train_subset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcdb663",
   "metadata": {},
   "source": [
    "# Model Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4292003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf7034ee64d481988f089e71a22643d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jiewang\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9833f7f802584c2787e70c3b7ddb2e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_valid/roc_auc': 0.7680990833089902,\n",
       " 'eval_valid/average_precision': 0.4821933667885799,\n",
       " 'eval_valid/f1_score': 0.44631901840490795,\n",
       " 'eval_valid/precision': 0.36014851485148514,\n",
       " 'eval_valid/recall': 0.5866935483870968,\n",
       " 'eval_valid/accuracy': 0.7435168738898756,\n",
       " 'eval_valid/best_hit1': 0.7157258064516129,\n",
       " 'eval_valid/best_hit3': 0.8487903225806451,\n",
       " 'eval_valid/best_hit5': 0.9153225806451613,\n",
       " 'eval_valid/best_hit10': 1.0,\n",
       " 'eval_valid/best_hit20': 1.0,\n",
       " 'eval_valid/best_hit50': 1.0,\n",
       " 'eval_valid/best_hit100': 1.0,\n",
       " 'eval_valid/best_reciprocal_rank': 0.802284946236559,\n",
       " 'eval_valid/worst_hit1': 0.7157258064516129,\n",
       " 'eval_valid/worst_hit3': 0.8487903225806451,\n",
       " 'eval_valid/worst_hit5': 0.9153225806451613,\n",
       " 'eval_valid/worst_hit10': 1.0,\n",
       " 'eval_valid/worst_hit20': 1.0,\n",
       " 'eval_valid/worst_hit50': 1.0,\n",
       " 'eval_valid/worst_hit100': 1.0,\n",
       " 'eval_valid/worst_reciprocal_rank': 0.802284946236559}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers.evaluation import SentenceEvaluator\n",
    "# Create a custom evaluator using your existing evaluation function\n",
    "class CustomMRREvaluator(SentenceEvaluator):\n",
    "    def __init__(self, validation_data, name=\"custom_eval\"):\n",
    "        self.validation_data = validation_data\n",
    "        self.name = name\n",
    "        \n",
    "    def __call__(self, model, output_path=None, epoch=None, steps=None):\n",
    "        # Use your existing evaluation function\n",
    "        eval_results = evaluate_embedding_similarity_with_mrr(model, self.validation_data)\n",
    "        \n",
    "        # Return the main metric (MRR) for model selection\n",
    "        eval_results = {f\"{self.name}/{k}\": v for k, v in eval_results.items()}\n",
    "        return eval_results\n",
    "    \n",
    "\n",
    "# Create custom evaluator using your existing function\n",
    "evaluator_valid = CustomMRREvaluator(condition_matching_valid, name=\"eval_valid\")\n",
    "evaluator_train_matching = CustomMRREvaluator(condition_matching_train_subset, name=\"train_matching\")\n",
    "evaluator_train_relation = CustomMRREvaluator(condition_relation_train_subset, name=\"train_relation\")\n",
    "\n",
    "evaluator_valid(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "068c3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer, SentenceTransformerTrainingArguments\n",
    "\n",
    "max_saves = 4\n",
    "\n",
    "epoch_num = 10\n",
    "batch_size = args.batch_size\n",
    "\n",
    "wandb_report_steps = 256\n",
    "arg_eval_steps = 2048\n",
    "arg_saving_steps = arg_eval_steps * 2\n",
    "\n",
    "learning_rate = 2e-5\n",
    "\n",
    "\n",
    "loss_func = losses.ContrastiveLoss(model=model)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Create training arguments equivalent to your custom training loop\n",
    "training_args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=epoch_num,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    learning_rate=learning_rate,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=arg_eval_steps,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=arg_saving_steps,\n",
    "    save_total_limit=max_saves,\n",
    "    logging_steps=wandb_report_steps,\n",
    "    run_name=output_dir,\n",
    "    seed=seed,\n",
    "    data_seed=seed,\n",
    "    report_to=\"wandb\" if not args.test_mode else \"none\",\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_drop_last=False,\n",
    "    dataloader_num_workers=0,  # Avoid multiprocessing issues on Windows\n",
    "    metric_for_best_model=\"eval_valid/roc_auc\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "733a579d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 15:15:45 - Starting SentenceTransformer training. Model saved to: output/finetune_initial/2025-10-02_15-10-28 (Elapsed: 316.57s, Since last: 34.95s)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff05c23d83fe4c90a5a5c7b735e43fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78690 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0113, 'grad_norm': 0.07827557623386383, 'learning_rate': 6.506544668954125e-07, 'epoch': 0.03}\n",
      "{'loss': 0.0067, 'grad_norm': 0.042671654373407364, 'learning_rate': 1.301308933790825e-06, 'epoch': 0.07}\n",
      "{'loss': 0.005, 'grad_norm': 0.023665642365813255, 'learning_rate': 1.951963400686237e-06, 'epoch': 0.1}\n",
      "{'loss': 0.0044, 'grad_norm': 0.021462224423885345, 'learning_rate': 2.60261786758165e-06, 'epoch': 0.13}\n",
      "{'loss': 0.0041, 'grad_norm': 0.026749519631266594, 'learning_rate': 3.253272334477062e-06, 'epoch': 0.16}\n",
      "{'loss': 0.004, 'grad_norm': 0.023066626861691475, 'learning_rate': 3.903926801372474e-06, 'epoch': 0.2}\n",
      "{'loss': 0.0039, 'grad_norm': 0.018647313117980957, 'learning_rate': 4.554581268267887e-06, 'epoch': 0.23}\n",
      "{'loss': 0.0037, 'grad_norm': 0.03143948316574097, 'learning_rate': 5.2052357351633e-06, 'epoch': 0.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946f19bfcd8341c4add909b919d6798e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8457a5f90b443ccb07938562b0b0aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53bdab3bab284f6e99bffbb17d8e2d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184c12ec0679487abdeb997d55f36e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73470919674d4eb5954e2dc4ce86aada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff892b90c68446ccb29b5c910d546d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_valid/roc_auc': 0.7756002309115442, 'eval_valid/average_precision': 0.4621983271783827, 'eval_valid/f1_score': 0.41245136186770426, 'eval_valid/precision': 0.2717948717948718, 'eval_valid/recall': 0.8548387096774194, 'eval_valid/accuracy': 0.5708703374777975, 'eval_valid/best_hit1': 0.6915322580645161, 'eval_valid/best_hit3': 0.8306451612903226, 'eval_valid/best_hit5': 0.9092741935483871, 'eval_valid/best_hit10': 1.0, 'eval_valid/best_hit20': 1.0, 'eval_valid/best_hit50': 1.0, 'eval_valid/best_hit100': 1.0, 'eval_valid/best_reciprocal_rank': 0.7875672043010753, 'eval_valid/worst_hit1': 0.6915322580645161, 'eval_valid/worst_hit3': 0.8306451612903226, 'eval_valid/worst_hit5': 0.9092741935483871, 'eval_valid/worst_hit10': 1.0, 'eval_valid/worst_hit20': 1.0, 'eval_valid/worst_hit50': 1.0, 'eval_valid/worst_hit100': 1.0, 'eval_valid/worst_reciprocal_rank': 0.7875672043010753, 'eval_train_matching/roc_auc': 0.796510080161091, 'eval_train_matching/average_precision': 0.5146340767190489, 'eval_train_matching/f1_score': 0.47954545454545455, 'eval_train_matching/precision': 0.3573243014394581, 'eval_train_matching/recall': 0.7288428324697754, 'eval_train_matching/accuracy': 0.6905405405405406, 'eval_train_matching/best_hit1': 0.792, 'eval_train_matching/best_hit3': 0.9, 'eval_train_matching/best_hit5': 0.952, 'eval_train_matching/best_hit10': 1.0, 'eval_train_matching/best_hit20': 1.0, 'eval_train_matching/best_hit50': 1.0, 'eval_train_matching/best_hit100': 1.0, 'eval_train_matching/best_reciprocal_rank': 0.8591333333333333, 'eval_train_matching/worst_hit1': 0.69, 'eval_train_matching/worst_hit3': 0.856, 'eval_train_matching/worst_hit5': 0.916, 'eval_train_matching/worst_hit10': 1.0, 'eval_train_matching/worst_hit20': 1.0, 'eval_train_matching/worst_hit50': 1.0, 'eval_train_matching/worst_hit100': 1.0, 'eval_train_matching/worst_reciprocal_rank': 0.7922150793650794, 'eval_train_relation/roc_auc': 0.5739404868628797, 'eval_train_relation/average_precision': 0.6320679525265205, 'eval_train_relation/f1_score': 0.4759388563879977, 'eval_train_relation/precision': 0.6750535331905781, 'eval_train_relation/recall': 0.36753133197318566, 'eval_train_relation/accuracy': 0.4988269265475546, 'eval_train_relation/best_hit1': 0.576, 'eval_train_relation/best_hit3': 0.92, 'eval_train_relation/best_hit5': 0.984, 'eval_train_relation/best_hit10': 1.0, 'eval_train_relation/best_hit20': 1.0, 'eval_train_relation/best_hit50': 1.0, 'eval_train_relation/best_hit100': 1.0, 'eval_train_relation/best_reciprocal_rank': 0.7511333333333334, 'eval_train_relation/worst_hit1': 0.0, 'eval_train_relation/worst_hit3': 0.1, 'eval_train_relation/worst_hit5': 0.228, 'eval_train_relation/worst_hit10': 0.622, 'eval_train_relation/worst_hit20': 0.97, 'eval_train_relation/worst_hit50': 1.0, 'eval_train_relation/worst_hit100': 1.0, 'eval_train_relation/worst_reciprocal_rank': 0.1478314330421128, 'eval_sequential_score': 0.5739404868628797, 'eval_runtime': 3.4969, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 0.26}\n",
      "{'loss': 0.0036, 'grad_norm': 0.017199957743287086, 'learning_rate': 5.855890202058712e-06, 'epoch': 0.29}\n",
      "{'loss': 0.0035, 'grad_norm': 0.028971994295716286, 'learning_rate': 6.506544668954124e-06, 'epoch': 0.33}\n",
      "{'loss': 0.0034, 'grad_norm': 0.021218936890363693, 'learning_rate': 7.1571991358495366e-06, 'epoch': 0.36}\n",
      "{'loss': 0.0033, 'grad_norm': 0.021432271227240562, 'learning_rate': 7.807853602744949e-06, 'epoch': 0.39}\n",
      "{'loss': 0.0033, 'grad_norm': 0.02024254947900772, 'learning_rate': 8.458508069640363e-06, 'epoch': 0.42}\n",
      "{'loss': 0.0033, 'grad_norm': 0.022289413958787918, 'learning_rate': 9.109162536535773e-06, 'epoch': 0.46}\n",
      "{'loss': 0.0031, 'grad_norm': 0.020935971289873123, 'learning_rate': 9.759817003431187e-06, 'epoch': 0.49}\n",
      "{'loss': 0.0031, 'grad_norm': 0.021221255883574486, 'learning_rate': 1.04104714703266e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef5b3f40e8a46f29e0351d098c445cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865bbf3702934f2897f272db8b78c4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3393bc77cbe49a39886d49550f9abb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91d8c83ed2f498f9571f039c1459733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b6dc6277734c3d931885664af0cda0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a64e47e87f74b58964d10c3cbaee772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_valid/roc_auc': 0.781222614029963, 'eval_valid/average_precision': 0.470859385346768, 'eval_valid/f1_score': 0.4044838860345633, 'eval_valid/precision': 0.2632218844984802, 'eval_valid/recall': 0.8729838709677419, 'eval_valid/accuracy': 0.5470692717584369, 'eval_valid/best_hit1': 0.6995967741935484, 'eval_valid/best_hit3': 0.8346774193548387, 'eval_valid/best_hit5': 0.9314516129032258, 'eval_valid/best_hit10': 1.0, 'eval_valid/best_hit20': 1.0, 'eval_valid/best_hit50': 1.0, 'eval_valid/best_hit100': 1.0, 'eval_valid/best_reciprocal_rank': 0.7945564516129031, 'eval_valid/worst_hit1': 0.6995967741935484, 'eval_valid/worst_hit3': 0.8346774193548387, 'eval_valid/worst_hit5': 0.9314516129032258, 'eval_valid/worst_hit10': 1.0, 'eval_valid/worst_hit20': 1.0, 'eval_valid/worst_hit50': 1.0, 'eval_valid/worst_hit100': 1.0, 'eval_valid/worst_reciprocal_rank': 0.7945564516129031, 'eval_train_matching/roc_auc': 0.8051521871116982, 'eval_train_matching/average_precision': 0.5147229242801051, 'eval_train_matching/f1_score': 0.48601206801974767, 'eval_train_matching/precision': 0.35610932475884244, 'eval_train_matching/recall': 0.7651122625215889, 'eval_train_matching/accuracy': 0.683445945945946, 'eval_train_matching/best_hit1': 0.802, 'eval_train_matching/best_hit3': 0.902, 'eval_train_matching/best_hit5': 0.96, 'eval_train_matching/best_hit10': 1.0, 'eval_train_matching/best_hit20': 1.0, 'eval_train_matching/best_hit50': 1.0, 'eval_train_matching/best_hit100': 1.0, 'eval_train_matching/best_reciprocal_rank': 0.8636666666666667, 'eval_train_matching/worst_hit1': 0.702, 'eval_train_matching/worst_hit3': 0.854, 'eval_train_matching/worst_hit5': 0.922, 'eval_train_matching/worst_hit10': 1.0, 'eval_train_matching/worst_hit20': 1.0, 'eval_train_matching/worst_hit50': 1.0, 'eval_train_matching/worst_hit100': 1.0, 'eval_train_matching/worst_reciprocal_rank': 0.7972960317460318, 'eval_train_relation/roc_auc': 0.6231128641698702, 'eval_train_relation/average_precision': 0.6679560398907727, 'eval_train_relation/f1_score': 0.5641025641025641, 'eval_train_relation/precision': 0.7096774193548387, 'eval_train_relation/recall': 0.46808510638297873, 'eval_train_relation/accuracy': 0.5520664140046923, 'eval_train_relation/best_hit1': 0.624, 'eval_train_relation/best_hit3': 0.958, 'eval_train_relation/best_hit5': 0.996, 'eval_train_relation/best_hit10': 1.0, 'eval_train_relation/best_hit20': 1.0, 'eval_train_relation/best_hit50': 1.0, 'eval_train_relation/best_hit100': 1.0, 'eval_train_relation/best_reciprocal_rank': 0.787, 'eval_train_relation/worst_hit1': 0.0, 'eval_train_relation/worst_hit3': 0.098, 'eval_train_relation/worst_hit5': 0.23, 'eval_train_relation/worst_hit10': 0.662, 'eval_train_relation/worst_hit20': 0.97, 'eval_train_relation/worst_hit50': 1.0, 'eval_train_relation/worst_hit100': 1.0, 'eval_train_relation/worst_reciprocal_rank': 0.15116037705132, 'eval_sequential_score': 0.6231128641698702, 'eval_runtime': 3.4278, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 15:32:53 - Saving model checkpoint to output/finetune_initial/2025-10-02_15-10-28\\checkpoint-4096\n",
      "2025-10-02 15:32:53 - Save model to output/finetune_initial/2025-10-02_15-10-28\\checkpoint-4096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.003, 'grad_norm': 0.018925417214632034, 'learning_rate': 1.106112593722201e-05, 'epoch': 0.55}\n",
      "{'loss': 0.0029, 'grad_norm': 0.0170204546302557, 'learning_rate': 1.1711780404117424e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0029, 'grad_norm': 0.02700810879468918, 'learning_rate': 1.2362434871012836e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m     13\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting SentenceTransformer training. Model saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain(resume_from_checkpoint\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel_checkpoint \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmodel_checkpoint \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Save the final model\u001b[39;00m\n\u001b[0;32m     17\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model()\n",
      "File \u001b[1;32mc:\\Users\\jiewang\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   2124\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   2125\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   2126\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   2127\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   2128\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jiewang\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2481\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2475\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2476\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2478\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2479\u001b[0m )\n\u001b[0;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2487\u001b[0m ):\n\u001b[0;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\jiewang\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:3612\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   3611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3612\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3613\u001b[0m     \u001b[38;5;66;03m# Finally we need to normalize the loss for reporting\u001b[39;00m\n\u001b[0;32m   3614\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jiewang\\AppData\\Local\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:2241\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2241\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jiewang\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    523\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jiewang\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m _engine_run_backward(\n\u001b[0;32m    290\u001b[0m     tensors,\n\u001b[0;32m    291\u001b[0m     grad_tensors_,\n\u001b[0;32m    292\u001b[0m     retain_graph,\n\u001b[0;32m    293\u001b[0m     create_graph,\n\u001b[0;32m    294\u001b[0m     inputs,\n\u001b[0;32m    295\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    296\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    297\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jiewang\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the trainer\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_all,\n",
    "    eval_dataset=None,  # Using custom evaluator instead\n",
    "    loss=loss_func,\n",
    "    evaluator=[evaluator_valid, evaluator_train_matching, evaluator_train_relation],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "logger.log(f\"Starting SentenceTransformer training. Model saved to: {output_dir}\")\n",
    "trainer.train(resume_from_checkpoint=args.model_checkpoint if args.model_checkpoint != \"none\" else None)\n",
    "\n",
    "# Save the final model\n",
    "trainer.save_model()\n",
    "logger.log(f\"Training completed. Model saved to {output_dir}\")\n",
    "logger.done()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
